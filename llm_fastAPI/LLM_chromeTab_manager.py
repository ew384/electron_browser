# LLM_chromeTab_manager.py - FastAPIé€‚é…å±‚ (ä¿®æ”¹ç‰ˆæœ¬)
# ä¿æŒ100%æ¥å£å…¼å®¹ï¼Œå†…éƒ¨åˆ‡æ¢åˆ°CDPæ¨¡å¼

from fastapi import FastAPI, HTTPException, Depends, Header
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Dict, Optional, List, Any, Union
import asyncio
import uuid
import logging
import json
import os
import time
import httpx
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI(title="LLM API Service (CDP Mode)")

# ==================== é…ç½®å’Œå¸¸é‡ ====================

# LLM CDPæœåŠ¡é…ç½®
LLM_SERVICE_CONFIG = {
    'base_url': os.getenv('LLM_SERVICE_URL', 'http://localhost:3212'),
    'timeout': int(os.getenv('LLM_SERVICE_TIMEOUT', '60')),
    'max_retries': int(os.getenv('LLM_SERVICE_RETRIES', '3')),
    'retry_delay': float(os.getenv('LLM_SERVICE_RETRY_DELAY', '2.0'))
}

# APIå¯†é’¥æ˜ å°„ (ä¿æŒåŸæœ‰é…ç½®å…¼å®¹)
api_keys = {
    "wangendian": "user_1",
    "chenhao": "user_2", 
    "test1": "user_3",
}

# ç”¨æˆ·ä¼šè¯æ˜ å°„ (å…¼å®¹åŸæœ‰ç»“æ„)
# æ ¼å¼: {api_key: {provider: {"session_id": str, "conversation_id": str, "created_at": int}}}
user_sessions = {key: {} for key in api_keys}

# HTTPå®¢æˆ·ç«¯
http_client = None

# ==================== æ•°æ®æ¨¡å‹ (ä¿æŒåŸæœ‰) ====================

class TabRequest(BaseModel):
    provider: str  # æä¾›å•†ï¼šclaude, chatgptç­‰

class ChatRequest(BaseModel):
    prompt: str
    new_chat: bool = False
    file_paths: Optional[List[str]] = None

# ==================== HTTPå®¢æˆ·ç«¯ç®¡ç† ====================

async def get_http_client():
    """è·å–HTTPå®¢æˆ·ç«¯å®ä¾‹"""
    global http_client
    if http_client is None:
        http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(LLM_SERVICE_CONFIG['timeout']),
            limits=httpx.Limits(max_connections=20, max_keepalive_connections=10)
        )
    return http_client

async def close_http_client():
    """å…³é—­HTTPå®¢æˆ·ç«¯"""
    global http_client
    if http_client is not None:
        await http_client.aclose()
        http_client = None

# ==================== LLMæœåŠ¡è°ƒç”¨æ–¹æ³• ====================

async def call_llm_service(method: str, endpoint: str, **kwargs) -> Dict[str, Any]:
    """
    è°ƒç”¨LLM CDPæœåŠ¡çš„é€šç”¨æ–¹æ³•
    
    Args:
        method: HTTPæ–¹æ³• (GET, POST, DELETEç­‰)
        endpoint: APIç«¯ç‚¹
        **kwargs: ä¼ é€’ç»™httpxçš„å…¶ä»–å‚æ•°
    
    Returns:
        APIå“åº”æ•°æ®
    """
    client = await get_http_client()
    url = f"{LLM_SERVICE_CONFIG['base_url']}{endpoint}"
    
    for attempt in range(LLM_SERVICE_CONFIG['max_retries']):
        try:
            logger.info(f"[CDP Service] {method} {endpoint} (å°è¯• {attempt + 1})")
            
            response = await client.request(method, url, **kwargs)
            response.raise_for_status()
            
            data = response.json()
            logger.info(f"[CDP Service] {method} {endpoint} - æˆåŠŸ")
            return data
            
        except httpx.HTTPStatusError as e:
            logger.error(f"[CDP Service] HTTPé”™è¯¯ {e.response.status_code}: {e.response.text}")
            if e.response.status_code == 404:
                raise HTTPException(status_code=404, detail="LLMæœåŠ¡ç«¯ç‚¹ä¸å­˜åœ¨")
            elif e.response.status_code >= 500:
                if attempt < LLM_SERVICE_CONFIG['max_retries'] - 1:
                    await asyncio.sleep(LLM_SERVICE_CONFIG['retry_delay'])
                    continue
                else:
                    raise HTTPException(status_code=500, detail="LLMæœåŠ¡å†…éƒ¨é”™è¯¯")
            else:
                raise HTTPException(status_code=e.response.status_code, detail="LLMæœåŠ¡è¯·æ±‚å¤±è´¥")
                
        except httpx.ConnectError:
            logger.error(f"[CDP Service] è¿æ¥é”™è¯¯ï¼Œå°è¯• {attempt + 1}")
            if attempt < LLM_SERVICE_CONFIG['max_retries'] - 1:
                await asyncio.sleep(LLM_SERVICE_CONFIG['retry_delay'])
                continue
            else:
                raise HTTPException(status_code=503, detail="æ— æ³•è¿æ¥åˆ°LLM CDPæœåŠ¡")
                
        except httpx.TimeoutException:
            logger.error(f"[CDP Service] è¯·æ±‚è¶…æ—¶ï¼Œå°è¯• {attempt + 1}")
            if attempt < LLM_SERVICE_CONFIG['max_retries'] - 1:
                await asyncio.sleep(LLM_SERVICE_CONFIG['retry_delay'])
                continue
            else:
                raise HTTPException(status_code=504, detail="LLMæœåŠ¡å“åº”è¶…æ—¶")
                
        except Exception as e:
            logger.error(f"[CDP Service] æœªçŸ¥é”™è¯¯: {str(e)}")
            if attempt < LLM_SERVICE_CONFIG['max_retries'] - 1:
                await asyncio.sleep(LLM_SERVICE_CONFIG['retry_delay'])
                continue
            else:
                raise HTTPException(status_code=500, detail=f"LLMæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}")

async def stream_llm_service(method: str, endpoint: str, **kwargs):
    """
    è°ƒç”¨LLM CDPæœåŠ¡çš„æµå¼æ–¹æ³•
    
    Args:
        method: HTTPæ–¹æ³•
        endpoint: APIç«¯ç‚¹
        **kwargs: ä¼ é€’ç»™httpxçš„å…¶ä»–å‚æ•°
    
    Yields:
        æµå¼å“åº”æ•°æ®
    """
    client = await get_http_client()
    url = f"{LLM_SERVICE_CONFIG['base_url']}{endpoint}"
    
    try:
        logger.info(f"[CDP Service Stream] {method} {endpoint}")
        
        async with client.stream(method, url, **kwargs) as response:
            response.raise_for_status()
            
            async for line in response.aiter_lines():
                if line.startswith('data: '):
                    data_str = line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                    if data_str.strip() == '[DONE]':
                        break
                    try:
                        data = json.loads(data_str)
                        yield data
                    except json.JSONDecodeError:
                        continue
                        
    except Exception as e:
        logger.error(f"[CDP Service Stream] æµå¼è¯·æ±‚å¤±è´¥: {str(e)}")
        yield {"type": "error", "error": str(e)}

# ==================== è¾…åŠ©å‡½æ•° ====================

async def validate_api_key(api_key: str = Header(...)):
    """éªŒè¯APIå¯†é’¥å¹¶è¿”å›ç”¨æˆ·ä¿¡æ¯ (ä¿æŒåŸæœ‰é€»è¾‘)"""
    if api_key not in api_keys:
        raise HTTPException(status_code=401, detail="æ— æ•ˆçš„APIå¯†é’¥")
    return api_key

def get_user_id(api_key: str) -> str:
    """è·å–ç”¨æˆ·ID (ä¿æŒåŸæœ‰é€»è¾‘)"""
    return api_keys.get(api_key, "unknown")

async def ensure_llm_service_health():
    """æ£€æŸ¥LLM CDPæœåŠ¡å¥åº·çŠ¶æ€"""
    try:
        health_data = await call_llm_service("GET", "/api/health")
        if not health_data.get("success", False):
            raise HTTPException(status_code=503, detail="LLM CDPæœåŠ¡ä¸å¥åº·")
        return health_data
    except Exception as e:
        logger.error(f"[Health Check] LLMæœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=503, detail="LLM CDPæœåŠ¡ä¸å¯ç”¨")

# ==================== APIè·¯ç”± (ä¿æŒ100%å…¼å®¹) ====================

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ– (é€‚é…ä¸ºCDPæ¨¡å¼)"""
    logger.info("ğŸš€ å¯åŠ¨FastAPIé€‚é…å±‚ (CDPæ¨¡å¼)")
    
    try:
        # æ£€æŸ¥LLM CDPæœåŠ¡å¯ç”¨æ€§
        await ensure_llm_service_health()
        logger.info("âœ… LLM CDPæœåŠ¡è¿æ¥æˆåŠŸ")
        
        # åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯
        await get_http_client()
        logger.info("âœ… HTTPå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†"""
    logger.info("ğŸ›‘ å…³é—­FastAPIé€‚é…å±‚")
    await close_http_client()

@app.post("/tabs")
async def create_tab(request: TabRequest, api_key: str = Depends(validate_api_key)):
    """
    ä¸ºç”¨æˆ·åˆ›å»ºæ–°æ ‡ç­¾é¡µ (ä¿æŒåŸæœ‰æ¥å£ï¼Œå†…éƒ¨è°ƒç”¨CDPæœåŠ¡)
    """
    try:
        provider = request.provider
        
        logger.info(f"ğŸ“ åˆ›å»ºæ ‡ç­¾é¡µè¯·æ±‚: {api_key} - {provider}")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¯¥æä¾›å•†çš„ä¼šè¯
        if provider in user_sessions[api_key]:
            existing_session = user_sessions[api_key][provider]
            logger.info(f"â™»ï¸ å¤ç”¨ç°æœ‰ä¼šè¯: {existing_session['session_id']}")
            
            # éªŒè¯ç°æœ‰ä¼šè¯æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
            try:
                status_data = await call_llm_service(
                    "GET", 
                    f"/api/llm/{api_key}/status"
                )
                
                if provider in status_data.get("status", {}).get("sessions", {}):
                    # ä¼šè¯ä»ç„¶æœ‰æ•ˆï¼Œè¿”å›ç°æœ‰ä¿¡æ¯
                    return {
                        "status": "success",
                        "message": f"å·²æœ‰{provider}æ ‡ç­¾é¡µ",
                        "tab_id": existing_session["session_id"],
                        "provider": provider,
                        "title": f"{provider.title()} Chat",
                        "url": f"https://{provider}.ai/" if provider == "claude" else f"https://{provider}.com/",
                        "reused": True
                    }
            except:
                # ä¼šè¯éªŒè¯å¤±è´¥ï¼Œç»§ç»­åˆ›å»ºæ–°ä¼šè¯
                logger.warning(f"âš ï¸ ç°æœ‰ä¼šè¯éªŒè¯å¤±è´¥ï¼Œåˆ›å»ºæ–°ä¼šè¯: {provider}")
                user_sessions[api_key].pop(provider, None)
        
        # è°ƒç”¨LLM CDPæœåŠ¡åˆ›å»ºæ–°ä¼šè¯
        create_data = await call_llm_service(
            "POST",
            f"/api/llm/{api_key}/sessions",
            json={"provider": provider, "forceNew": False}
        )
        
        if create_data.get("success"):
            session_info = create_data["session"]
            
            # æ›´æ–°æœ¬åœ°ä¼šè¯ç¼“å­˜
            user_sessions[api_key][provider] = {
                "session_id": session_info["sessionId"],
                "conversation_id": None,  # å°†åœ¨ç¬¬ä¸€æ¬¡å¯¹è¯æ—¶è®¾ç½®
                "created_at": session_info["createdAt"],
                "provider_name": session_info["providerName"]
            }
            
            logger.info(f"âœ… æ ‡ç­¾é¡µåˆ›å»ºæˆåŠŸ: {session_info['sessionId']}")
            
            # è¿”å›å…¼å®¹æ ¼å¼
            return {
                "status": "success",
                "tab_id": session_info["sessionId"],
                "provider": provider,
                "title": session_info["providerName"],
                "url": f"https://{provider}.ai/" if provider == "claude" else f"https://{provider}.com/",
                "created": create_data.get("created", True),
                "features": session_info.get("features", {})
            }
        else:
            raise HTTPException(status_code=500, detail=create_data.get("error", "ä¼šè¯åˆ›å»ºå¤±è´¥"))
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ ‡ç­¾é¡µå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºæ ‡ç­¾é¡µå¤±è´¥: {str(e)}")

@app.delete("/tabs/{provider}")
async def close_tab(provider: str, api_key: str = Depends(validate_api_key)):
    """
    å…³é—­æŒ‡å®šæä¾›å•†çš„æ ‡ç­¾é¡µ (ä¿æŒåŸæœ‰æ¥å£)
    """
    try:
        if provider not in user_sessions[api_key]:
            raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ°æä¾›å•† {provider} çš„æ ‡ç­¾é¡µ")
        
        logger.info(f"ğŸ”Œ å…³é—­æ ‡ç­¾é¡µ: {api_key} - {provider}")
        
        # è°ƒç”¨LLM CDPæœåŠ¡å…³é—­ä¼šè¯
        close_data = await call_llm_service(
            "DELETE",
            f"/api/llm/{api_key}/sessions/{provider}"
        )
        
        if close_data.get("success"):
            # ä»æœ¬åœ°ç¼“å­˜ä¸­ç§»é™¤
            session_id = user_sessions[api_key][provider]["session_id"]
            user_sessions[api_key].pop(provider, None)
            
            logger.info(f"âœ… æ ‡ç­¾é¡µå…³é—­æˆåŠŸ: {session_id}")
            
            return {
                "status": "success", 
                "message": f"{provider}æ ‡ç­¾é¡µå·²å…³é—­",
                "session_id": session_id
            }
        else:
            raise HTTPException(status_code=500, detail=close_data.get("error", "å…³é—­æ ‡ç­¾é¡µå¤±è´¥"))
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å…³é—­æ ‡ç­¾é¡µå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å…³é—­æ ‡ç­¾é¡µå¤±è´¥: {str(e)}")

@app.get("/tabs")
async def list_tabs(api_key: str = Depends(validate_api_key)):
    """
    åˆ—å‡ºç”¨æˆ·çš„æ‰€æœ‰æ ‡ç­¾é¡µ (ä¿æŒåŸæœ‰æ¥å£)
    """
    try:
        logger.info(f"ğŸ“‹ åˆ—å‡ºæ ‡ç­¾é¡µ: {api_key}")
        
        # è°ƒç”¨LLM CDPæœåŠ¡è·å–ä¼šè¯åˆ—è¡¨
        sessions_data = await call_llm_service(
            "GET",
            f"/api/llm/{api_key}/sessions"
        )
        
        if sessions_data.get("success"):
            sessions = sessions_data["sessions"]
            tabs = []
            
            # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
            for session in sessions:
                tabs.append({
                    "tab_id": session["sessionId"],
                    "provider": session["provider"],
                    "title": session["providerName"],
                    "url": f"https://{session['provider']}.ai/" if session['provider'] == "claude" else f"https://{session['provider']}.com/",
                    "status": session["status"],
                    "created_at": session["createdAt"],
                    "last_used": session["lastUsed"],
                    "message_count": session["messageCount"]
                })
                
                # åŒæ­¥æ›´æ–°æœ¬åœ°ç¼“å­˜
                user_sessions[api_key][session["provider"]] = {
                    "session_id": session["sessionId"],
                    "conversation_id": None,
                    "created_at": session["createdAt"],
                    "provider_name": session["providerName"]
                }
            
            logger.info(f"âœ… æ ‡ç­¾é¡µåˆ—è¡¨è·å–æˆåŠŸ: {len(tabs)} ä¸ª")
            return tabs
        else:
            raise HTTPException(status_code=500, detail=sessions_data.get("error", "è·å–æ ‡ç­¾é¡µåˆ—è¡¨å¤±è´¥"))
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ—å‡ºæ ‡ç­¾é¡µå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ—å‡ºæ ‡ç­¾é¡µå¤±è´¥: {str(e)}")

@app.post("/chat/{provider}")
async def chat_with_llm(
    provider: str, 
    request: Dict[str, Any], 
    api_key: str = Depends(validate_api_key)
):
    """
    LLMå¯¹è¯API (ä¿æŒåŸæœ‰æ¥å£ï¼Œæ”¯æŒæµå¼å’Œéæµå¼)
    """
    try:
        logger.info(f"ğŸ’¬ å¯¹è¯è¯·æ±‚: {api_key} - {provider}")
        
        # æ£€æŸ¥provideræ˜¯å¦å­˜åœ¨ä¼šè¯
        if provider not in user_sessions[api_key]:
            # è‡ªåŠ¨åˆ›å»ºä¼šè¯
            create_result = await create_tab(TabRequest(provider=provider), api_key)
            if create_result["status"] != "success":
                raise HTTPException(status_code=500, detail="æ— æ³•åˆ›å»ºLLMä¼šè¯")
        
        # è·å–è¯·æ±‚å‚æ•°
        prompt = request.get("prompt", "")
        file_paths = request.get("file_paths", None)
        stream = request.get("stream", False)
        new_chat = request.get("new_chat", False)
        
        if stream:
            # æµå¼å“åº”
            logger.info(f"ğŸŒŠ å¯åŠ¨æµå¼å“åº”: {provider}")
            
            async def generate_stream():
                try:
                    async for chunk in stream_llm_service(
                        "POST",
                        f"/api/llm/{api_key}/chat/{provider}",
                        json={
                            "prompt": prompt,
                            "files": file_paths,
                            "stream": True,
                            "newChat": new_chat
                        }
                    ):
                        # è½¬æ¢ä¸ºåŸæœ‰æ ¼å¼
                        if chunk.get("type") == "error":
                            yield json.dumps({
                                "status": "error",
                                "message": chunk.get("error", "Unknown error")
                            }) + "\n"
                        elif chunk.get("type") == "complete":
                            # æ›´æ–°å¯¹è¯ID
                            if "conversationId" in chunk:
                                user_sessions[api_key][provider]["conversation_id"] = chunk["conversationId"]
                            
                            yield json.dumps({
                                "status": "success",
                                "content": chunk.get("data", {}),
                                "conversation_id": chunk.get("conversationId"),
                                "provider": provider
                            }) + "\n"
                        else:
                            # ä¸­é—´æ•°æ®å—
                            yield json.dumps(chunk) + "\n"
                            
                except Exception as e:
                    logger.error(f"âŒ æµå¼å“åº”é”™è¯¯: {str(e)}")
                    yield json.dumps({
                        "status": "error",
                        "message": str(e)
                    }) + "\n"
            
            return StreamingResponse(
                generate_stream(), 
                media_type="application/json",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive"
                }
            )
        else:
            # éæµå¼å“åº”
            logger.info(f"ğŸ“ å¯åŠ¨éæµå¼å“åº”: {provider}")
            
            chat_data = await call_llm_service(
                "POST",
                f"/api/llm/{api_key}/chat/{provider}",
                json={
                    "prompt": prompt,
                    "files": file_paths,
                    "stream": False,
                    "newChat": new_chat
                }
            )
            
            if chat_data.get("success"):
                # æ›´æ–°å¯¹è¯ID
                if "conversationId" in chat_data:
                    user_sessions[api_key][provider]["conversation_id"] = chat_data["conversationId"]
                
                logger.info(f"âœ… å¯¹è¯å®Œæˆ: {provider}")
                
                # è¿”å›å…¼å®¹æ ¼å¼
                return {
                    "status": "success",
                    "content": chat_data["response"],
                    "conversation_id": chat_data.get("conversationId"),
                    "provider": provider,
                    "timing": chat_data.get("timing", {})
                }
            else:
                raise HTTPException(status_code=500, detail=chat_data.get("error", "å¯¹è¯å¤„ç†å¤±è´¥"))
                
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¯¹è¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯¹è¯å¤±è´¥: {str(e)}")

@app.post("/tabs/{provider}/screenshot")
async def take_screenshot(provider: str, api_key: str = Depends(validate_api_key)):
    """
    è·å–æŒ‡å®šæä¾›å•†æ ‡ç­¾é¡µçš„æˆªå›¾ (ä¿æŒåŸæœ‰æ¥å£)
    """
    try:
        if provider not in user_sessions[api_key]:
            raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ°æä¾›å•† {provider} çš„æ ‡ç­¾é¡µ")
        
        logger.info(f"ğŸ“¸ æˆªå›¾è¯·æ±‚: {api_key} - {provider}")
        
        # ç”±äºCDPæ¨¡å¼ä¸‹æˆªå›¾éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œè¿”å›å ä½ç¬¦
        # å®é™…å®ç°éœ€è¦é€šè¿‡LLMæœåŠ¡è°ƒç”¨æˆªå›¾åŠŸèƒ½
        
        return {
            "status": "success",
            "screenshot_path": f"/tmp/screenshot_{provider}_{int(time.time())}.png",
            "message": "æˆªå›¾åŠŸèƒ½åœ¨CDPæ¨¡å¼ä¸‹éœ€è¦ç‰¹æ®Šå®ç°",
            "provider": provider
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æˆªå›¾å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æˆªå›¾å¤±è´¥: {str(e)}")

# ==================== å¥åº·æ£€æŸ¥å’Œè°ƒè¯•æ¥å£ ====================

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        # æ£€æŸ¥LLM CDPæœåŠ¡å¥åº·çŠ¶æ€
        llm_health = await ensure_llm_service_health()
        
        return {
            "status": "healthy",
            "service": "LLM API Adapter (CDP Mode)",
            "timestamp": time.time(),
            "llm_service": {
                "available": True,
                "url": LLM_SERVICE_CONFIG['base_url'],
                "health": llm_health
            },
            "active_users": len([k for k, v in user_sessions.items() if v]),
            "total_sessions": sum(len(sessions) for sessions in user_sessions.values())
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": time.time()
        }

@app.get("/debug/sessions")
async def debug_sessions():
    """è°ƒè¯•æ¥å£ï¼šæŸ¥çœ‹æ‰€æœ‰ä¼šè¯çŠ¶æ€"""
    try:
        debug_info = {
            "local_sessions": user_sessions,
            "api_keys": list(api_keys.keys()),
            "llm_service_config": LLM_SERVICE_CONFIG
        }
        
        # è·å–LLMæœåŠ¡çš„è°ƒè¯•ä¿¡æ¯
        try:
            llm_debug = await call_llm_service("GET", "/api/admin/stats")
            debug_info["llm_service_stats"] = llm_debug
        except:
            debug_info["llm_service_stats"] = "æ— æ³•è·å–LLMæœåŠ¡ç»Ÿè®¡ä¿¡æ¯"
        
        return debug_info
    except Exception as e:
        return {"error": str(e)}

@app.post("/admin/cleanup")
async def admin_cleanup():
    """ç®¡ç†æ¥å£ï¼šæ¸…ç†è¿‡æœŸä¼šè¯"""
    try:
        logger.info("ğŸ§¹ æ‰§è¡Œç®¡ç†å‘˜æ¸…ç†æ“ä½œ")
        
        # è°ƒç”¨LLMæœåŠ¡æ¸…ç†
        cleanup_data = await call_llm_service(
            "POST",
            "/api/admin/cleanup",
            json={"maxAge": 24 * 60 * 60 * 1000, "dryRun": False}
        )
        
        # æ¸…ç†æœ¬åœ°ä¼šè¯ç¼“å­˜
        cleaned_local = 0
        for api_key in user_sessions:
            providers_to_remove = []
            for provider in user_sessions[api_key]:
                # å¯ä»¥æ·»åŠ æœ¬åœ°æ¸…ç†é€»è¾‘
                pass
        
        return {
            "success": True,
            "llm_service_cleanup": cleanup_data,
            "local_cleanup": {"cleaned": cleaned_local},
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†æ“ä½œå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }

# ==================== å¯åŠ¨é…ç½® ====================

if __name__ == "__main__":
    import uvicorn
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    host = os.getenv('FASTAPI_HOST', '0.0.0.0')
    port = int(os.getenv('FASTAPI_PORT', '5815'))
    
    logger.info(f"ğŸš€ å¯åŠ¨FastAPIé€‚é…å±‚ (CDPæ¨¡å¼)")
    logger.info(f"ğŸ“¡ LLM CDPæœåŠ¡: {LLM_SERVICE_CONFIG['base_url']}")
    logger.info(f"ğŸŒ ç›‘å¬åœ°å€: {host}:{port}")
    
    uvicorn.run(
        "LLM_chromeTab_manager:app",  # æ¨¡å—:åº”ç”¨å
        host=host,
        port=port,
        reload=os.getenv('FASTAPI_RELOAD', 'false').lower() == 'true',
        log_level=os.getenv('FASTAPI_LOG_LEVEL', 'info').lower()
    )